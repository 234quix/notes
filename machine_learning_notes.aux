\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Rules of thumb}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Resources}{1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Week 6 - Machine Learning Diagnostics}{1}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Learning Curves - figuring out if you have high bias or high variance}{1}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Debugging a learning algorithm}{3}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Skewed Classes}{4}{subsection.3.3}}
\@writefile{toc}{\contentsline {paragraph}{Precision}{4}{section*.1}}
\@writefile{toc}{\contentsline {paragraph}{Recall}{4}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{F score }{4}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}very large datasets}{4}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Week 7: Unsupervised Learning }{5}{section.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Week 9:Anomaly Detection }{5}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Normal distribution}{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Parameter Estimation}{5}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Density estimation}{5}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Anomaly detection algorithm}{6}{subsubsection.5.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Notes Coursera Week 10: Large Scale Machine Learning }{6}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Vid1: Learning with Large Datasets}{6}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Vid2: Computationally efficient methods: Stochastic Gradient Descent}{6}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Left: High variance, should add more data, Right: high bias, more data won't help, should add more features, or more hidden units to neural networks}}{7}{figure.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Vid3: Mini-Batch Gradient Descent}{7}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Vid4: Stochastic Gradient Descent Convergence}{7}{subsection.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Vid5: Online Learning}{7}{subsection.6.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Vid6: Map reduce and Data Parallelism}{7}{subsection.6.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Week 11: Where to allocate scarce resources?}{7}{section.7}}
